{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4a1ed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import pairwise2\n",
    "from Bio.Seq import Seq\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "def aligned(ref_seq,query_seq):\n",
    "    # Define the gap penalty\n",
    "\n",
    "    ref_seq = Seq(ref_seq.upper())\n",
    "    query_seq = Seq(query_seq.upper())\n",
    "    # Perform global sequence alignment with custom gap penalty\n",
    "    # 0.5 points are deducted when opening a gap, and 0.1 points are\n",
    "    alignments = pairwise2.align.globalms(ref_seq, query_seq, 3, -1, -5, -0.1)\n",
    "    #print(alignments)\n",
    "    query_aligned = alignments[0][1]\n",
    "    ref_aligned = alignments[0][0]\n",
    "    return query_aligned, ref_aligned\n",
    "\n",
    "\n",
    "\n",
    "def short_DNA_align(seq1,seq2):\n",
    "    # Define the scoring parameters\n",
    "    match_score = 1\n",
    "    mismatch_penalty = -1\n",
    "    gap_open_penalty = -2\n",
    "    gap_extension_penalty = -1\n",
    "\n",
    "    # Perform the pairwise alignment using globalds function\n",
    "    alignments = pairwise2.align.globalms(seq1, seq2, match_score, mismatch_penalty, gap_open_penalty, gap_extension_penalty)\n",
    "\n",
    "    # Extract the first (and only) alignment from the list of alignments\n",
    "    alignment = alignments[0]\n",
    "\n",
    "    # Calculate the number of gaps and mismatches in the alignment\n",
    "    num_gaps = alignment[0].count(\"-\")+alignment[1].count(\"-\")\n",
    "    num_mismatches = sum(1 for a, b in zip(*alignment[:2]) if a != b and a != \"-\" and b != \"-\")\n",
    "\n",
    "    # Calculate the total number of gaps and mismatches\n",
    "    total_errors = num_gaps + num_mismatches\n",
    "\n",
    "    # Print the alignment and the total number of gaps and mismatches\n",
    "    return total_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c56c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_insertions(insertions):\n",
    "    \"\"\"\n",
    "    This function takes in a list of insertion information as tuples, where the first value in each tuple is the position\n",
    "    and the second value is the DNA base. It combines adjacent insertions at the same position and returns a new list of tuples,\n",
    "    where the first value is the position of the insertion and the second value is a string representing the combined bases.\n",
    "    \"\"\"\n",
    "    combined = []\n",
    "    current_pos = None\n",
    "    current_bases = ''\n",
    "    for pos, base in insertions:\n",
    "        if current_pos is None:\n",
    "            current_pos = pos\n",
    "            current_bases = base\n",
    "        elif pos == current_pos + len(current_bases):\n",
    "            current_bases += base\n",
    "        else:\n",
    "            combined.append((current_pos, current_bases))\n",
    "            current_pos = pos\n",
    "            current_bases = base\n",
    "    combined.append((current_pos, current_bases))\n",
    "    return combined\n",
    "\n",
    "def insertion_deletion_position(alignment_len,insertion,deletion):\n",
    "    insertion_fixed = []\n",
    "    deletion_fixed = []\n",
    "    fix_index = 0\n",
    "    for num in range(alignment_len):\n",
    "        if len(insertion) >=1:\n",
    "            if insertion[0][0] == num:\n",
    "                insertion_fixed.append((insertion[0][0]+fix_index, insertion[0][1]))\n",
    "                fix_index -= len(insertion[0][1])\n",
    "                \n",
    "                insertion = insertion[1:]\n",
    "                \n",
    "            \n",
    "        if len(deletion) >=1:    \n",
    "            if deletion[0][0] == num:\n",
    "                deletion_fixed.append((deletion[0][0]+fix_index,deletion[0][1]))\n",
    "                deletion = deletion[1:]\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "    return insertion_fixed, deletion_fixed\n",
    "        \n",
    "    \n",
    "\n",
    "def alignment_prase(ref_seq,query_seq):\n",
    "    # remove gaps at the start or end of the sequences\n",
    "    alignment_len = len(ref_seq)\n",
    "    removed = 0\n",
    "    while ref_seq.startswith(\"-\"):\n",
    "\n",
    "        ref_seq = ref_seq[1:]\n",
    "        query_seq = query_seq[1:]\n",
    "        \n",
    "    while query_seq.startswith(\"-\"):\n",
    "        removed = removed + 1\n",
    "        ref_seq = ref_seq[1:]\n",
    "        query_seq = query_seq[1:]        \n",
    "    while ref_seq.endswith(\"-\") or query_seq.endswith(\"-\"):\n",
    "        ref_seq = ref_seq[:-1]\n",
    "        query_seq = query_seq[:-1]\n",
    "    # initialize variables for tracking insertion, deletion, and mismatch counts\n",
    "    insertion_count = 0\n",
    "    deletion_count = 0\n",
    "    mismatch_count = 0\n",
    "    insertion = []\n",
    "    deletion = []\n",
    "    mismatch = []\n",
    "    # iterate over each position in the sequences\n",
    "    \n",
    "    for i in range(len(ref_seq)):\n",
    "        if ref_seq[i] == query_seq[i]:\n",
    "            # the bases match, do nothing\n",
    "            pass\n",
    "        elif query_seq[i] == \"-\":\n",
    "            # this is a deletion in the query sequence\n",
    "            \n",
    "            deletion_tuple = (i+removed+1,ref_seq[i])\n",
    "            deletion.append(deletion_tuple)\n",
    "            deletion_count += 1\n",
    "        elif ref_seq[i] == \"-\":\n",
    "            # this is an insertion in the query sequence\n",
    "            \n",
    "            insertion_tuple = (i+removed+1,query_seq[i])\n",
    "            insertion.append(insertion_tuple)\n",
    "            insertion_count += 1\n",
    "        else:\n",
    "            # this is a substitution\n",
    "            mismatch_count += 1\n",
    "            mismatch_tuple = (i+removed-insertion_count+1,ref_seq[i],query_seq[i])\n",
    "            \n",
    "            mismatch.append(mismatch_tuple)\n",
    "    #print(insertion)\n",
    "    insertion = combine_insertions(insertion)\n",
    "    deletion = combine_insertions(deletion)\n",
    "    insertion_fix, deletion_fix = insertion_deletion_position(alignment_len,insertion,deletion)\n",
    "    return deletion_fix, insertion_fix,mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68f46896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expect(df,expect_seq):\n",
    "    no_gaps_ref = df['Reference_Sequence'][0].replace(\"-\", \"\")\n",
    "    expext_aligned, ref_aligned = aligned(no_gaps_ref,expect_seq)\n",
    "    #print( expext_aligned, ref_aligned )\n",
    "    deletion, insertion,mismatch = main(ref_aligned,expext_aligned)\n",
    "    return deletion, insertion,mismatch\n",
    "def dict_change (dict_,name, value):\n",
    "    if name not in dict_:\n",
    "        dict_[name]= value\n",
    "    else:\n",
    "        dict_[name] += value\n",
    "    return dict_\n",
    "def insertion_check (insertion ,insertion_exp ,mismath_gap_allow):\n",
    "    for tup in insertion:\n",
    "        error_ins = short_DNA_align(tup[1],insertion_exp[0][1])\n",
    "        if error_ins < mismath_gap_allow:\n",
    "            return True\n",
    "            break\n",
    "    return False\n",
    "\n",
    "def read_fasta(file_path):\n",
    "    sequences = {}\n",
    "    with open(file_path, 'r') as fasta_file:\n",
    "        sequence_id = None\n",
    "        sequence = ''\n",
    "        for line in fasta_file:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                if sequence_id:\n",
    "                    sequences[sequence_id] = sequence\n",
    "                sequence_id = line[1:]\n",
    "                sequence = ''\n",
    "            else:\n",
    "                sequence += line\n",
    "        if sequence_id:\n",
    "            sequences[sequence_id] = sequence\n",
    "    return sequences\n",
    "\n",
    "\n",
    "def search_files(directory):\n",
    "    lst = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            lst.append(file_path)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6929442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(df_alleles,Locus,exp_dict):\n",
    "    dict_classified = {'unmodified': 0,'deletion_only': 0,'unrelated_insertion': 0,'perfect_editing': 0, 'mismatch_only': 0,\n",
    "         'perfect_insertion_with_mismatch': 0, 'deletion_and_mismatch': 0,'imperfect_insertion': 0,\n",
    "          'perfect_insertion_with_deletion': 0,'perfect_insertion_with_deletion_and_mismatch':0}\n",
    "    deletion_exp, insertion_exp,mismatch_exp =exp_dict[Locus]\n",
    "    for num in range(len(df_alleles)):\n",
    "        deletion, insertion, mismatch = alignment_prase(df_alleles['Reference_Sequence'][num],df_alleles['Aligned_Sequence'][num])\n",
    "        if deletion == [] and insertion == [] and mismatch == []:\n",
    "            dict_classified = dict_change(dict_classified,'unmodified', df_alleles['%Reads'][num])\n",
    "\n",
    "        elif len(insertion) != 0:\n",
    "            if insertion == insertion_exp:\n",
    "                if deletion == deletion_exp and mismatch == mismatch_exp:\n",
    "                    dict_classified = dict_change(dict_classified,'perfect_editing', df_alleles['%Reads'][num])\n",
    "                elif deletion == deletion_exp:\n",
    "                    dict_classified = dict_change(dict_classified,'perfect_insertion_with_mismatch', df_alleles['%Reads'][num])\n",
    "                elif mismatch == mismatch_exp:\n",
    "                    dict_classified = dict_change(dict_classified,'perfect_insertion_with_deletion', df_alleles['%Reads'][num])\n",
    "                else:\n",
    "                    dict_classified = dict_change(dict_classified,'perfect_insertion_with_deletion_and_mismatch', df_alleles['%Reads'][num])\n",
    "            elif all(tup in insertion_exp for tup in insertion):\n",
    "                dict_classified = dict_change(dict_classified,'perfect_insertion_with_insertion', df_alleles['%Reads'][num])\n",
    "            else:\n",
    "                if insertion_check(insertion ,insertion_exp ,mismath_gap_allow) == True:\n",
    "                    dict_classified = dict_change(dict_classified,'imperfect_insertion', df_alleles['%Reads'][num])\n",
    "                else:    \n",
    "                    dict_classified = dict_change(dict_classified,'unrelated_insertion', df_alleles['%Reads'][num])\n",
    "        elif len(deletion) != 0:\n",
    "            if len(mismatch) == 0:\n",
    "                dict_classified = dict_change(dict_classified,'deletion_only', df_alleles['%Reads'][num])\n",
    "            else:\n",
    "                dict_classified = dict_change(dict_classified,'deletion_and_mismatch', df_alleles['%Reads'][num])\n",
    "        else:\n",
    "            dict_classified = dict_change(dict_classified,'mismatch_only', df_alleles['%Reads'][num])\n",
    "\n",
    "\n",
    "            pass\n",
    "    # Define the data as a dictionary\n",
    "\n",
    "    return dict_classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c82f4786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_check_columns(csv_path, column_names):\n",
    "    \"\"\"\n",
    "    This function reads a CSV file into a pandas DataFrame and checks if specific columns exist.\n",
    "    \"\"\"\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Check if the specified columns are in the DataFrame\n",
    "    columns_exist = all(column in df.columns for column in column_names)\n",
    "    \n",
    "    return df, columns_exist\n",
    "def check_key_in_dict(dictionary, key_to_check):\n",
    "    \"\"\"\n",
    "    This function checks if a given key exists in a dictionary.\n",
    "\n",
    "    \"\"\"\n",
    "    return key_to_check in dictionary\n",
    "\n",
    "def contains_substring(str_list, substring):\n",
    "    # Check if the substring is present in any of the strings in the list\n",
    "    return any(substring in s for s in str_list)\n",
    "def process_dataframe_rows(df,path_lst,fasta_sequences):\n",
    "    \"\"\"\n",
    "    This function iterates through a DataFrame row by row, checks each row using a provided function,\n",
    "    and separates the rows into two DataFrames based on the check result.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Sample_id,Locus,Sample_id_fail,Locus_fail,reason = [],[],[],[],[]\n",
    "  \n",
    "    for _, row in df.iterrows():\n",
    "        if contains_substring(path_lst,row['Sample_id']) == False or check_key_in_dict(fasta_sequences,row['Locus']) == False:\n",
    "            if contains_substring(path_lst,row['Sample_id']) == False:\n",
    "                reason.append('no sequence file found')\n",
    "                Sample_id_fail.append(row['Sample_id'])\n",
    "                Locus_fail.append(row['Locus'])\n",
    "            else:\n",
    "                reason.append('no reference seuqnce found')\n",
    "\n",
    "                Sample_id_fail.append(row['Sample_id'])\n",
    "                Locus_fail.append(row['Locus'])\n",
    "        else:\n",
    "                Sample_id.append(row['Sample_id'])\n",
    "                Locus.append(row['Locus'])\n",
    "    dict_pass = {'Sample_id':Sample_id,'Locus':Locus}\n",
    "    dict_fail = {'Sample_id':Sample_id_fail,'Locus':Locus_fail,'reason':reason}\n",
    "    df_pass = pd.DataFrame.from_dict(dict_pass)\n",
    "    df_fail = pd.DataFrame.from_dict(dict_fail)\n",
    "    return df_pass , df_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8102138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
